<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Projects - Sajay</title>
    <link rel="stylesheet" href="layout.css">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <!-- Background Effects Container -->
    <div id="background-effects">
        <div id="dappled-light">
            <div id="glow"></div>
            <div id="glow-bounce"></div>
            <div class="perspective">
                <div id="leaves">
                    <svg style="width: 0; height: 0; position: absolute;">
                        <defs>
                            <filter id="wind" x="-20%" y="-20%" width="140%" height="140%">
                                <feTurbulence type="fractalNoise" numOctaves="2" seed="1">
                                    <animate attributeName="baseFrequency" dur="16s" keyTimes="0;0.33;0.66;1"
                                        values="0.005 0.003;0.01 0.009;0.008 0.004;0.005 0.003" repeatCount="indefinite" />
                                </feTurbulence>
                                <feDisplacementMap in="SourceGraphic">
                                    <animate attributeName="scale" dur="20s" keyTimes="0;0.25;0.5;0.75;1"
                                        values="45;55;75;55;45" repeatCount="indefinite" />
                                </feDisplacementMap>
                            </filter>
                        </defs>
                    </svg>
                </div>
                <div id="blinds">
                    <div class="shutters">
                        <div class="shutter"></div>
                        <div class="shutter"></div>
                        <div class="shutter"></div>
                        <div class="shutter"></div>
                        <div class="shutter"></div>
                        <div class="shutter"></div>
                        <div class="shutter"></div>
                        <div class="shutter"></div>
                        <div class="shutter"></div>
                        <div class="shutter"></div>
                        <div class="shutter"></div>
                        <div class="shutter"></div>
                        <div class="shutter"></div>
                        <div class="shutter"></div>
                        <div class="shutter"></div>
                    </div>
                    <div class="vertical">
                        <div class="bar"></div>
                        <div class="bar"></div>
                    </div>
                </div>
            </div>
            <div id="progressive-blur">
                <div></div>
            </div>
        </div>
    </div>

    <!-- Main Scrollable Container -->
    <div id="scroll-container">
        <header class="header">
            <div class="header-content">
                <a href="/" class="logo">Sajay</a>
                <nav class="nav">
                    <a href="/" class="nav-item">Home</a>
                    <a href="/blog.html" class="nav-item">Blogs</a>
                    <a class="nav-item active">Cool stuff</a>
                    <button class="theme-toggle">
                        <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor"
                             stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                            <circle cx="12" cy="12" r="5"/>
                            <path d="M12 1v2M12 21v2M4.22 4.22l1.42 1.42M18.36 18.36l1.42 1.42M1 12h2M21 12h2
                                     M4.22 19.78l1.42-1.42M18.36 5.64l1.42-1.42"/>
                        </svg>
                    </button>
                </nav>
            </div>
        </header>

        <!-- Projects Content -->
        <main class="projects-container">
            <!-- Current Research Section -->
            <section class="current-research">
                <div class="research-content">
                    <h2>Active Research</h2>
                    <h3>Triad</h3>
                    <p class="research-description">
                    <b>Unsupervised dense multimodal feature grounding of audio-visual-text information alignment.</b><br>
                        While approaches such as ImageBind, CLIP, show extremely promising results in finding associations between modalities (answering if an image and text are related or not), they struggle to localize the exact features that align with each other. My current research focuses on learning fine-grained, localized relationships rather than just global alignment.
                    </p>
                    <div class="research-highlights">
                        <div style="display: flex; justify-content: space-between; align-items: center;">
                            <h3>Key Directions</h3>
                            <a href="https://github.com/SajayR/Triad" aria-label="View Project on GitHub">
                                <svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor">
                                    <path fill-rule="evenodd" clip-rule="evenodd"
                                          d="M12 2C6.477 2 2 6.463 2 11.97c0 4.404 2.865 8.14 6.839 9.458.5.092.682-.216.682-.48 0-.236-.008-.864-.013-1.695-2.782.602-3.369-1.337-3.369-1.337-.454-1.151-1.11-1.458-1.11-1.458-.908-.618.069-.606.069-.606 1.003.07 1.531 1.027 1.531 1.027.892 1.524 2.341 1.084 2.91.828.092-.643.35-1.083.636-1.332-2.22-.251-4.555-1.107-4.555-4.927 0-1.088.39-1.979 1.029-2.675-.103-.252-.446-1.266.098-2.638 0 0 .84-.268 2.75 1.022A9.606 9.606 0 0112 6.82c.85.004 1.705.114 2.504.336 1.909-1.29 2.747-1.022 2.747-1.022.546 1.372.202 2.386.1 2.638.64.696 1.028 1.587 1.028 2.675 0 3.83-2.339 4.673-4.566 4.92.359.307.678.915.678 1.846 0 1.332-.012 2.407-.012 2.734 0 .267.18.577.688.48C19.137 20.107 22 16.373 22 11.969 22 6.463 17.522 2 12 2z"/>
                                </svg>
                            </a>
                        </div>
                        <ul>
                            <li>Completely unsupervised multimodal feature localization</li>
                            <li>Features of semantically similar objects align naturally between modalities</li>
                            <li>Promptable information retrieval for multimodal tasks</li>
                        </ul>
                    </div>
                    <div class="research-links">
                        <h3>Related Work</h3>
                        <div class="links-grid">
                            <a href="https://arxiv.org/abs/2406.05629" class="research-link">
                                <span class="link-title">DenseAV: Separating the "Chirp" from the "Chat"</span>
                                <span class="link-description">Establishes SOTA dense correspondence between audio and visual features</span>
                            </a>
                            <a href="https://arxiv.org/abs/2305.05665" class="research-link">
                                <span class="link-title">ImageBind</span>
                                <span class="link-description">Global alignment between 6 modalities-image, audio, text, depth, thermal, and radar</span>
                            </a>
                        </div>
                    </div>
                </div>
            </section>

            <div class="section-divider"></div>

            <!-- Other Projects Section -->
            <section class="other-projects">
                <h2>Other Projects</h2>
                <div class="projects-grid">
                    <article class="project-card">
                        <div class="project-content">
                            <h3>AV-Align</h3>
                            <p>Base implementation of a dense audio-visual alignment model for audio prompted visual localization.</p>
                            <div class="project-links">
                                <a href="https://github.com/SajayR/AV-Align" aria-label="View Project on GitHub">
                                    <svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor">
                                        <path fill-rule="evenodd" clip-rule="evenodd"
                                              d="M12 2C6.477 2 2 6.463 2 11.97c0 4.404 2.865 8.14 6.839 9.458.5.092.682-.216.682-.48 0-.236-.008-.864-.013-1.695-2.782.602-3.369-1.337-3.369-1.337-.454-1.151-1.11-1.458-1.11-1.458-.908-.618.069-.606.069-.606 1.003.07 1.531 1.027 1.531 1.027.892 1.524 2.341 1.084 2.91.828.092-.643.35-1.083.636-1.332-2.22-.251-4.555-1.107-4.555-4.927 0-1.088.39-1.979 1.029-2.675-.103-.252-.446-1.266.098-2.638 0 0 .84-.268 2.75 1.022A9.606 9.606 0 0112 6.82c.85.004 1.705.114 2.504.336 1.909-1.29 2.747-1.022 2.747-1.022.546 1.372.202 2.386.1 2.638.64.696 1.028 1.587 1.028 2.675 0 3.83-2.339 4.673-4.566 4.92.359.307.678.915.678 1.846 0 1.332-.012 2.407-.012 2.734 0 .267.18.577.688.48C19.137 20.107 22 16.373 22 11.969 22 6.463 17.522 2 12 2z"/>
                                    </svg>
                                </a>
                            </div>
                        </div>
                    </article>
                    <article class="project-card">
                        <div class="project-content">
                            <h3>State-space model for rider's intent prediction</h3>
                            <p>Published as a part of RIP competition paper at ICPR 2024, a Mamba2-based model for predicting rider's intent. <br/>Winning method for the competition hosted by IIITH for the first prize of $1000. ;) </p>
                            <div class="project-links">
                                <a href="https://github.com/SajayR/ICPR-RIP" aria-label="View Project on GitHub">
                                    <svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor">
                                        <path fill-rule="evenodd" clip-rule="evenodd"
                                              d="M12 2C6.477 2 2 6.463 2 11.97c0 4.404 2.865 8.14 6.839 9.458.5.092.682-.216.682-.48 0-.236-.008-.864-.013-1.695-2.782.602-3.369-1.337-3.369-1.337-.454-1.151-1.11-1.458-1.11-1.458-.908-.618.069-.606.069-.606 1.003.07 1.531 1.027 1.531 1.027.892 1.524 2.341 1.084 2.91.828.092-.643.35-1.083.636-1.332-2.22-.251-4.555-1.107-4.555-4.927 0-1.088.39-1.979 1.029-2.675-.103-.252-.446-1.266.098-2.638 0 0 .84-.268 2.75 1.022A9.606 9.606 0 0112 6.82c.85.004 1.705.114 2.504.336 1.909-1.29 2.747-1.022 2.747-1.022.546 1.372.202 2.386.1 2.638.64.696 1.028 1.587 1.028 2.675 0 3.83-2.339 4.673-4.566 4.92.359.307.678.915.678 1.846 0 1.332-.012 2.407-.012 2.734 0 .267.18.577.688.48C19.137 20.107 22 16.373 22 11.969 22 6.463 17.522 2 12 2z"/>
                                    </svg>
                                </a>
                            </div>
                        </div>
                    </article>
                    <article class="project-card">
                        <div class="project-content">
                            <h3>FudgeGrad</h3>
                            <p>An autograd engine inspired by PyTorch from scratch. (In progress)</p>
                            <div class="project-links">
                                <a href="https://github.com/SajayR/FudgeGrad" aria-label="View Project on GitHub">
                                    <svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor">
                                        <path fill-rule="evenodd" clip-rule="evenodd"
                                              d="M12 2C6.477 2 2 6.463 2 11.97c0 4.404 2.865 8.14 6.839 9.458.5.092.682-.216.682-.48 0-.236-.008-.864-.013-1.695-2.782.602-3.369-1.337-3.369-1.337-.454-1.151-1.11-1.458-1.11-1.458-.908-.618.069-.606.069-.606 1.003.07 1.531 1.027 1.531 1.027.892 1.524 2.341 1.084 2.91.828.092-.643.35-1.083.636-1.332-2.22-.251-4.555-1.107-4.555-4.927 0-1.088.39-1.979 1.029-2.675-.103-.252-.446-1.266.098-2.638 0 0 .84-.268 2.75 1.022A9.606 9.606 0 0112 6.82c.85.004 1.705.114 2.504.336 1.909-1.29 2.747-1.022 2.747-1.022.546 1.372.202 2.386.1 2.638.64.696 1.028 1.587 1.028 2.675 0 3.83-2.339 4.673-4.566 4.92.359.307.678.915.678 1.846 0 1.332-.012 2.407-.012 2.734 0 .267.18.577.688.48C19.137 20.107 22 16.373 22 11.969 22 6.463 17.522 2 12 2z"/>
                                    </svg>
                                </a>
                            </div>
                        </div>
                    </article>
                    <article class="project-card">
                        <div class="project-content">
                            <h3>HTT: Hearing through time</h3>
                            <p>An extension to traditional audio localization methods that depend on individual visual frames to localize sound sources in videos by directly training on entire sequences of frames with a TimesFormer backbone.</p>
                            <div class="project-links">
                                <a href="https://github.com/SajayR/HTT" aria-label="View Project on GitHub">
                                    <svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor">
                                        <path fill-rule="evenodd" clip-rule="evenodd"
                                              d="M12 2C6.477 2 2 6.463 2 11.97c0 4.404 2.865 8.14 6.839 9.458.5.092.682-.216.682-.48 0-.236-.008-.864-.013-1.695-2.782.602-3.369-1.337-3.369-1.337-.454-1.151-1.11-1.458-1.11-1.458-.908-.618.069-.606.069-.606 1.003.07 1.531 1.027 1.531 1.027.892 1.524 2.341 1.084 2.91.828.092-.643.35-1.083.636-1.332-2.22-.251-4.555-1.107-4.555-4.927 0-1.088.39-1.979 1.029-2.675-.103-.252-.446-1.266.098-2.638 0 0 .84-.268 2.75 1.022A9.606 9.606 0 0112 6.82c.85.004 1.705.114 2.504.336 1.909-1.29 2.747-1.022 2.747-1.022.546 1.372.202 2.386.1 2.638.64.696 1.028 1.587 1.028 2.675 0 3.83-2.339 4.673-4.566 4.92.359.307.678.915.678 1.846 0 1.332-.012 2.407-.012 2.734 0 .267.18.577.688.48C19.137 20.107 22 16.373 22 11.969 22 6.463 17.522 2 12 2z"/>
                                    </svg>
                                </a>
                            </div>
                        </div>
                    </article>
                    <article class="project-card">
                        <div class="project-content">
                            <h3>LetMeSee</h3>
                            <p>Learned content-aware patch truncation for ViT models for improved efficiency</p>
                            <div class="project-links">
                                <a href="https://github.com/SajayR/LetMeSee" aria-label="View Project on GitHub">
                                    <svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor">
                                        <path fill-rule="evenodd" clip-rule="evenodd"
                                              d="M12 2C6.477 2 2 6.463 2 11.97c0 4.404 2.865 8.14 6.839 9.458.5.092.682-.216.682-.48 0-.236-.008-.864-.013-1.695-2.782.602-3.369-1.337-3.369-1.337-.454-1.151-1.11-1.458-1.11-1.458-.908-.618.069-.606.069-.606 1.003.07 1.531 1.027 1.531 1.027.892 1.524 2.341 1.084 2.91.828.092-.643.35-1.083.636-1.332-2.22-.251-4.555-1.107-4.555-4.927 0-1.088.39-1.979 1.029-2.675-.103-.252-.446-1.266.098-2.638 0 0 .84-.268 2.75 1.022A9.606 9.606 0 0112 6.82c.85.004 1.705.114 2.504.336 1.909-1.29 2.747-1.022 2.747-1.022.546 1.372.202 2.386.1 2.638.64.696 1.028 1.587 1.028 2.675 0 3.83-2.339 4.673-4.566 4.92.359.307.678.915.678 1.846 0 1.332-.012 2.407-.012 2.734 0 .267.18.577.688.48C19.137 20.107 22 16.373 22 11.969 22 6.463 17.522 2 12 2z"/>
                                    </svg>
                                </a>
                            </div>
                        </div>
                    </article>
                </div>
            </section>
        </main>
    </div>

    <script src="script.js"></script>
</body>
</html> 